Hello! This video will consist of two parts. In first part I am gonna show how to run this simple application and in the second pard part I will further explain the key imeplmentation details this program.Now let's see how it runs. I have packaged the program in jar file. Let's open the cml tool and run it  Type in db user name and pw, the crawling process has started...Basically we get these warning just because I used a library to run the java script locally to get dynamic generated content. So we ignore it. Now we can try to search the key word to find associated menu items. If I type “chicken”, we can see all the results related to the keyword chicken. Let's try another key word... We can see that the result will show the menu item as long as the key word in its title or its description If we can not find any menu item related to a particular key word, then the system will tell user the result is not found.Next we close the program and move to the implementation part.Next I am gonna introduce how I implement the key functionalities of this program.  This simple application has three components, web crawler, data storage and menu search. I try to make the parser more generic from the perspectives of both design and implementation. So we have a general parser and restaurant parser will implement this interface. The core functionality is implemented in RP. Let's see the what the restaurant parser does. First the parser will take in a base url and from this base url we start searching the contact url and menu url. If we are luckily enough we can find the contact page and menu page from the home page. But in some situation, we might not be able to find contact and menu page directly from home page, so we need to go to a depth first search the entire domain.  After we locate the contact page and menu page, we start to search the restaurant information. I use a regular expression to search for phone and address. although it might not be 100% accurate to use regex to search address but most of cases you can find a match and do not need to change the code. Then we save it to database. Next thing we search the menu item. Since the html format of two websites are different so I write custom searchMenuItem method. In order to do this I create custom parser extends from resparser. The only difference is that they have diff implementation of searchMenuItem. One thing worth to mention is that Allspice website use javascript to generate menu content dynamically so I use an external lib to simulate a browser and run the javascript locally and fetch the generated html. It can scale well for most dynamic generated content.  In the model part, the data model is relatively simple, each menu item is tied to a unique restaurant and the program will check whether db has existing record so that when we run multiple times there won’t be any duplicate record.The last thing is the search function. It will not only match the key word in the menu title but also find menu with key word in the description. Due to the time constraints, the application has some limitations. For example, it cannot get the menu information for all website. One thing we can do to improve it is to use ml or a dictionary to match the relevant content so we can have a more intelligent way to crawl the menu info.  The other thing we can improve is to build a custom recommendation system rather than just a simple key word match. For example, we can calculate the match score between a key word and the menu/ using some external nlp library. Or we can  give the restaurant that is close to user’s physical location a higher rank. Of course these features would need more investigations and more detailed requirements but def something we can look at in the next step. Thank you for listening.